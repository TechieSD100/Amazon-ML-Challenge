{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the constants from constants.py\n",
    "Import dependencies as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import entity_unit_map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining a function that maps each entity_name to its corresponding units.\n",
    "This function will apply the appropriate unit to each predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit(entity_name):\n",
    "    \"\"\"Return the possible units for a given entity name.\"\"\"\n",
    "    return entity_unit_map.get(entity_name, set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Format Predictions with Units\n",
    "Assuming that you have a dictionary or list of predictions where each prediction is associated with an entity name, format these predictions with the appropriate units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_units(entity_name, value):\n",
    "    \"\"\"Apply the correct unit based on the entity name.\"\"\"\n",
    "    units = get_unit(entity_name)\n",
    "    if not units:\n",
    "        return f\"{value}\"  # Return value without units if no units are defined for the entity\n",
    "    \n",
    "    # For simplicity, let's assume the first unit in the set is chosen\n",
    "    unit = next(iter(units))\n",
    "    return f\"{value} {unit}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Predictions with Units\n",
    "Generating predictions and using the apply_units function to format them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'\n",
    "\n",
    "# Load your test dataset\n",
    "test_data = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "entity_names = test_data['entity_name'].values\n",
    "\n",
    "# Assuming you have generated predictions\n",
    "# predictions should be a list or array of numeric values\n",
    "predictions = np.random.rand(len(entity_names))  # Example predictions\n",
    "\n",
    "# Apply units to the predictions\n",
    "formatted_predictions = [apply_units(entity, pred) for entity, pred in zip(entity_names, predictions)]\n",
    "\n",
    "# Create a DataFrame for the output\n",
    "output_df = pd.DataFrame({\n",
    "    'entity_name': entity_names,\n",
    "    'prediction': formatted_predictions\n",
    "})\n",
    "\n",
    "# Save the formatted output to a CSV file\n",
    "output_df.to_csv('formatted_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load and process the CSV file to a PKL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load the CSV file\n",
    "labels_df = pd.read_csv('formatted_predictions.csv')\n",
    "\n",
    "# Ensure 'prediction' column is of string type\n",
    "labels_df['prediction'] = labels_df['prediction'].astype(str)\n",
    "\n",
    "# Split the 'prediction' column into 'confidence' and 'unit'\n",
    "# We will manually handle cases where the split operation might fail\n",
    "def split_prediction(prediction):\n",
    "    parts = prediction.split(' ', 1)  # Split only on the first space\n",
    "    if len(parts) == 2:\n",
    "        return parts\n",
    "    else:\n",
    "        return [parts[0], '']  # Handle cases where there is no space\n",
    "\n",
    "# Apply the split function\n",
    "labels_df[['confidence', 'unit']] = labels_df['prediction'].apply(lambda x: pd.Series(split_prediction(x)))\n",
    "\n",
    "# Extract the 'unit' column for labels\n",
    "labels = labels_df['unit'].values\n",
    "\n",
    "# Encode labels if they are categorical\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Save encoded labels\n",
    "np.save('labels.npy', encoded_labels)\n",
    "\n",
    "# Optionally: Save the label encoder if you need to reverse the encoding later\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels.npy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load labels\n",
    "labels_df = pd.read_csv('formatted_predictions.csv')  # Replace with your labels file path\n",
    "\n",
    "# Assuming the labels are in a column named 'label'\n",
    "labels = labels_df['prediction'].values\n",
    "\n",
    "# Encode labels if they are categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Save encoded labels\n",
    "np.save('labels.npy', encoded_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
